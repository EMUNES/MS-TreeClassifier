{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('tlc': conda)",
   "display_name": "Python 3.8.5 64-bit ('tlc': conda)",
   "metadata": {
    "interpreter": {
     "hash": "7c33d18c879b8c16ea1940d8472bc6cf82c89fa81050fa6bd15d10c212b5b695"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### packages"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import pdb\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "import random\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torchvision import transforms as T\n",
    "from torchvision import models\n",
    "from efficientnet_pytorch import EfficientNet \n",
    "\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.special import softmax\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensor, ToTensorV2\n",
    "from albumentations import ImageOnlyTransform"
   ]
  },
  {
   "source": [
    "### global configurations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Those are the core configurations of this notebook. \n",
    "Read this carefully: \n",
    "\n",
    "- paths do not need to change unless you changed folder structure of this project \n",
    "- if you add more data (especially add a folder full of images under ./data/train), you should only need to alter *label_encoding*\n",
    "- each time you want to train and save a new model, please change *model_name* so you won't rewrite other's result\n",
    "- *epoch* stands for the total epochs of training. 8-15 should be sufficient for this task. You can add up epochs but you'd better do not want to surpass 20\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('./data/')\n",
    "path_train = path/'train'\n",
    "path_test = path/'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size, bs = 384, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(3, {&#39;Chinar&#39;: 0, &#39;Gauva&#39;: 1, &#39;Jamun&#39;: 2})"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# encode tree types to integer labels range from 0\n",
    "# the string must be the same as the folder name the ./data/train/xxx\n",
    "# which stands for the tree type that images belong to \n",
    "label_encoding = (\n",
    "    (\"Chinar\", 0), \n",
    "    (\"Gauva\", 1),\n",
    "    (\"Jamun\", 2),\n",
    ")\n",
    "num_labels = len(label_encoding)\n",
    "label_encoding = dict(label_encoding)\n",
    "num_labels, label_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model name that will be saved after all epochs\n",
    "model_name = 'baseline-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total epochs\n",
    "epoch = 12 "
   ]
  },
  {
   "source": [
    "## helper functions to load data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# puts all your images under different folders, for example:\n",
    "# - train \n",
    "# - - tree type 1\n",
    "# - - - all tree type 1 images...\n",
    "# - - tree type 2\n",
    "# - - - ...\n",
    "# - - tree type 3\n",
    "# - - - ...\n",
    "def list_all_train_files(path: Path):\n",
    "    '''Return all image file paths in a list\n",
    "\n",
    "    Returns:\n",
    "        files: a list contains all image file paths\n",
    "\n",
    "    Args:\n",
    "        path: the path that holds all the images\n",
    "    '''\n",
    "    files = []\n",
    "    for o in path.iterdir():\n",
    "        files.extend([f for f in o.iterdir()])\n",
    "    return files\n",
    "\n",
    "# for all files in the same folder\n",
    "# def list_all_train_files(path:Path):\n",
    "#     return [f for f in path.iterdir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "([WindowsPath(&#39;data/train/Chinar/0011_0001.JPG&#39;),\n  WindowsPath(&#39;data/train/Chinar/0011_0002.JPG&#39;),\n  WindowsPath(&#39;data/train/Chinar/0011_0003.JPG&#39;),\n  WindowsPath(&#39;data/train/Chinar/0011_0004.JPG&#39;),\n  WindowsPath(&#39;data/train/Chinar/0011_0005.JPG&#39;)],\n 1094)"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "train_fnames = list_all_train_files(path_train)\n",
    "train_fnames[:5], len(train_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "([], 0)"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "test_fnames = list_all_train_files(path_test)\n",
    "test_fnames[:5], len(test_fnames)"
   ]
  },
  {
   "source": [
    "## Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeDataset(Dataset):\n",
    "    def __init__(self, f_paths: list, transforms=None, is_test=False):\n",
    "        self.f_paths = f_paths    \n",
    "        self.transforms = transforms\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 1.get image file\n",
    "        img_path = self.f_paths[index]\n",
    "        image = np.array(Image.open(img_path), dtype=np.float32)\n",
    "\n",
    "        # transform?\n",
    "        if self.transforms:\n",
    "            image = self.transforms(**{'image': image})['image']\n",
    "\n",
    "        # test?\n",
    "        if self.is_test:\n",
    "            return image\n",
    "\n",
    "        # 2.get the corresponding label to this image\n",
    "        tree_type = str(img_path).split('\\\\')[-2]\n",
    "        label = label_encoding[tree_type]\n",
    "        target = torch.tensor([label], dtype=torch.long)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.f_paths)"
   ]
  },
  {
   "source": [
    "## model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeEfficientNet(nn.Module):\n",
    "    def __init__(self, model_name='efficientnet-b3', pool_type=F.adaptive_avg_pool2d):\n",
    "        super(TreeEfficientNet, self).__init__()\n",
    "        self.pool_type = pool_type\n",
    "        self.backbone = EfficientNet.from_pretrained(model_name)\n",
    "        \n",
    "        image_in_features = getattr(self.backbone, '_fc').in_features\n",
    "        self.efn_head = nn.Sequential(\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(image_in_features, 512),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(256, 128),\n",
    "        )\n",
    "        self.classifer = nn.Linear(128, num_labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        cnn_features = self.pool_type(self.backbone.extract_features(x), 1)\n",
    "        cnn_features = cnn_features.view(x.size(0), -1)\n",
    "        cnn_features = self.efn_head(cnn_features)\n",
    "\n",
    "        return self.classifer(cnn_features)"
   ]
  },
  {
   "source": [
    "## Focal Loss"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha, gamma):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, preds, truth):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        pt = criterion(preds, truth.to(dtype=torch.long))\n",
    "        log_pt = torch.log(pt)\n",
    "        focal_loss = self.alpha * (1-pt)**self.gamma * log_pt\n",
    "        return torch.mean(focal_loss)"
   ]
  },
  {
   "source": [
    "## helper functions for forward&backward propagation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get device\n",
    "\n",
    "def get_device():\n",
    "    return torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is just for cleaning the possible None values\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch = [(data, target) for (data, target) in batch if data is not None]\n",
    "    return default_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shit ton of augmentations using albumentations\n",
    "\n",
    "def get_augmentations(p=0.5, img_size=image_size):\n",
    "    # give pretrained image_net stats\n",
    "    imagenet_stats = {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}\n",
    "    \n",
    "    # this is for training\n",
    "    train_tfms = A.Compose([\n",
    "        # simple cutout regularization\n",
    "        A.Cutout(p=p),\n",
    "        # rotation\n",
    "        #A.RandomRotate90(p=p),\n",
    "        #A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=p),\n",
    "        # flip\n",
    "        A.Flip(p=p),\n",
    "        # one of color augmentation\n",
    "        A.OneOf([\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.2,\n",
    "                                      contrast_limit=0.2,),\n",
    "            A.HueSaturationValue(\n",
    "                hue_shift_limit=20,\n",
    "                sat_shift_limit=50,\n",
    "                val_shift_limit=50)\n",
    "        ], p=p),\n",
    "        # one of noise augmentation\n",
    "        A.OneOf([\n",
    "            A.IAAAdditiveGaussianNoise(),\n",
    "            A.GaussNoise()\n",
    "        ], p=p),\n",
    "        # one of blurring augmenation\n",
    "        A.OneOf([\n",
    "            A.MotionBlur(p=0.2),\n",
    "            A.MedianBlur(blur_limit=3, p=0.1),\n",
    "            A.Blur(blur_limit=3, p=0.1),\n",
    "        ], p=p),\n",
    "        # one of distortion\n",
    "        A.OneOf([\n",
    "            A.OpticalDistortion(p=0.3),\n",
    "            A.GridDistortion(p=0.1),\n",
    "            A.IAAPiecewiseAffine(p=0.3),\n",
    "        ], p=p),\n",
    "        A.Resize(img_size, img_size, always_apply=True),\n",
    "        # must do: to tensor\n",
    "        ToTensor(normalize=imagenet_stats),\n",
    "    ])\n",
    "    \n",
    "    # this is for TTA\n",
    "    test_tfms = A.Compose([\n",
    "        A.RandomRotate90(p=p),\n",
    "            A.Flip(p=p),\n",
    "            A.OneOf([\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.2,\n",
    "                                           contrast_limit=0.2,\n",
    "                                           ),\n",
    "                A.HueSaturationValue(\n",
    "                    hue_shift_limit=20,\n",
    "                    sat_shift_limit=50,\n",
    "                    val_shift_limit=50)\n",
    "            ], p=p),\n",
    "            A.OneOf([\n",
    "                A.IAAAdditiveGaussianNoise(),\n",
    "                A.GaussNoise(),\n",
    "            ], p=p),\n",
    "        ToTensor(normalize=imagenet_stats)\n",
    "        ])\n",
    "\n",
    "    valid_tfms = A.Compose([\n",
    "        ToTensor(normalize=imagenet_stats)\n",
    "    ])\n",
    "\n",
    "    return train_tfms, valid_tfms, test_tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_tfms, valid_tfms):\n",
    "    train_ds = TreeDataset(train_fnames, train_tfms)\n",
    "    valid_ds = TreeDataset(train_fnames, valid_tfms)\n",
    "    train_dl = DataLoader(dataset=train_ds, batch_size=bs, shuffle=True, num_workers=0, collate_fn=collate_fn)\n",
    "    valid_dl = DataLoader(dataset=valid_ds, batch_size=bs, shuffle=True, num_workers=0, collate_fn=collate_fn)\n",
    "    return train_dl, valid_dl"
   ]
  },
  {
   "source": [
    "## Set up our model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name='efficientnet-b3', lr=1e-5, wd=0.01, freeze_backbone=False, opt_fn=torch.optim.AdamW, device=None):\n",
    "    # 1. get device\n",
    "    device = device if device else get_device()\n",
    "    # 2.get our model\n",
    "    pool_type = F.adaptive_avg_pool2d\n",
    "    model = TreeEfficientNet(model_name=model_name, pool_type=pool_type)\n",
    "    if freeze_backbone:\n",
    "        for parameter in model.backbone.parameters():\n",
    "            parameter.requires_grad = False\n",
    "    # 3. get our optimizer for back propagation - AdamW tends to work better\n",
    "    optimizer = opt_fn(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    # 4. move our model to device\n",
    "    model.to(device)\n",
    "\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(xb, yb, model, loss_fn, opt, device, scheduler):\n",
    "    # forward\n",
    "    xb, yb = xb.to(device), yb.reshape(-1).to(device)\n",
    "    out = model(xb)\n",
    "    loss = loss_fn(out, yb)\n",
    "\n",
    "    # backward\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_step(xb, yb, model, loss_fn, device):\n",
    "    xb, yb = xb.to(device), yb.reshape(-1).to(device)\n",
    "    out = model(xb)\n",
    "    loss = loss_fn(out, yb)\n",
    "    \n",
    "    out = torch.sigmoid(out)\n",
    "    \n",
    "    return loss.item(), out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap up to a fit one cycle funcition\n",
    "def fit(epochs, train_dl, valid_dl, model, loss_fn, opt, device=None):\n",
    "    # set up device for data\n",
    "    device = device if device else get_device()\n",
    "    # set up scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, len(train_dl)*epochs)\n",
    "    val_accuracy_scores = []\n",
    "    \n",
    "    # creating a progress bar\n",
    "    mb = master_bar(range(epochs))\n",
    "    mb.write(['epochs', 'train_loss', 'valid_loss', 'accuracy'], table=True)\n",
    "    \n",
    "    # iterate 10 epochs\n",
    "    for epoch in mb:\n",
    "        trn_loss, val_loss = 0., 0.\n",
    "        val_preds = np.zeros((len(valid_dl.dataset), 3))\n",
    "        val_targets = np.zeros((len(valid_dl.dataset), 1))\n",
    "        val_scores = []\n",
    "        \n",
    "        # training mode\n",
    "        model.train()\n",
    "        \n",
    "        # for every batch, we step and collect training loss\n",
    "        for xb, yb in progress_bar(train_dl, parent=mb):\n",
    "            trn_loss += training_step(xb, yb, model=model, loss_fn=loss_fn, opt=opt, device=device, scheduler=scheduler)\n",
    "        trn_loss /= mb.child.total # 10\n",
    "        \n",
    "        # validation mode\n",
    "        # now we need valid_loss and val_score from the validatin steps (witout gradients of course)\n",
    "        with torch.no_grad():\n",
    "            for i, (xb, yb) in enumerate(progress_bar(valid_dl, parent=mb)):\n",
    "                loss, out = validation_step(xb, yb, model=model, loss_fn=loss_fn, device=device)\n",
    "                val_loss += loss\n",
    "                bs = xb.shape[0]\n",
    "                val_preds[i*bs: i*bs+bs] = out.cpu().numpy()\n",
    "                val_targets[i*bs: i*bs+bs]= yb.cpu().numpy()\n",
    "                \n",
    "        preds = np.argmax(softmax(val_preds, axis=1), axis=1)\n",
    "        true = val_targets.reshape(-1)\n",
    "        accuracy = accuracy_score(true, preds)\n",
    "        val_accuracy_scores.append(accuracy)\n",
    "        mb.write([epoch, f'{trn_loss:.6f}', f'{val_loss:.6f}', f'{accuracy:.6f}'], table=True)\n",
    "\n",
    "    return model, val_accuracy_scores"
   ]
  },
  {
   "source": [
    "## start training validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Loaded pretrained weights for efficientnet-b3\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='0' class='' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    \n"
     },
     "metadata": {}
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m&lt;ipython-input-19-ab7db9c4601f&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m&#39;efficientnet-b3&#39;\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----&gt; 9\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m&#39;#&#39;\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m20\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34mf&#39;STORING MODEL: baseline_model_{fold}\\n VAL_SCORE:{val_scores}&#39;\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf&#39;./models/baseline_model_{fold}.pth&#39;\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m&lt;ipython-input-18-8d8135cf203b&gt;\u001b[0m in \u001b[0;36mfit\u001b[1;34m(epochs, train_dl, valid_dl, model, loss_fn, opt, device)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m# for every batch, we step and collect training loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---&gt; 24\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[0mtrn_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mtrn_loss\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mmb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[1;31m# 10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramFile\\anaconda\\envs\\tlc\\lib\\site-packages\\fastprogress\\fastprogress.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---&gt; 41\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m&gt;=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramFile\\anaconda\\envs\\tlc\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--&gt; 363\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramFile\\anaconda\\envs\\tlc\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--&gt; 403\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramFile\\anaconda\\envs\\tlc\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---&gt; 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramFile\\anaconda\\envs\\tlc\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m&lt;listcomp&gt;\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---&gt; 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m&lt;ipython-input-8-34fe96a6dd5d&gt;\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m# transform?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---&gt; 14\u001b[1;33m             \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m&#39;image&#39;\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m&#39;image&#39;\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# test?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramFile\\anaconda\\envs\\tlc\\lib\\site-packages\\albumentations\\core\\composition.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, force_apply, **data)\u001b[0m\n\u001b[0;32m    174\u001b[0m                     \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--&gt; 176\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforce_apply\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_apply\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdual_start_end\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdual_start_end\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramFile\\anaconda\\envs\\tlc\\lib\\site-packages\\albumentations\\core\\composition.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, force_apply, **data)\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m32\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms_ps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--&gt; 223\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforce_apply\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramFile\\anaconda\\envs\\tlc\\lib\\site-packages\\albumentations\\imgaug\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---&gt; 38\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBasicIAATransform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramFile\\anaconda\\envs\\tlc\\lib\\site-packages\\albumentations\\core\\transforms_interface.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, force_apply, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                     )\n\u001b[0;32m     86\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---&gt; 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_with_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramFile\\anaconda\\envs\\tlc\\lib\\site-packages\\albumentations\\core\\transforms_interface.py\u001b[0m in \u001b[0;36mapply_with_params\u001b[1;34m(self, params, force_apply, **kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[0mtarget_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_target_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                 \u001b[0mtarget_dependencies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_dependence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--&gt; 100\u001b[1;33m                 \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtarget_dependencies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m                 \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramFile\\anaconda\\envs\\tlc\\lib\\site-packages\\albumentations\\imgaug\\transforms.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, img, deterministic_processor, **params)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic_processor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---&gt; 46\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdeterministic_processor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maugment_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramFile\\anaconda\\envs\\tlc\\lib\\site-packages\\imgaug\\augmenters\\meta.py\u001b[0m in \u001b[0;36maugment_image\u001b[1;34m(self, image, hooks)\u001b[0m\n\u001b[0;32m    769\u001b[0m             &quot;got shape %s.&quot; % (image.shape,))\n\u001b[0;32m    770\u001b[0m         \u001b[0miabase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_on_suspicious_single_image_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--&gt; 771\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maugment_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0maugment_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramFile\\anaconda\\envs\\tlc\\lib\\site-packages\\imgaug\\augmenters\\meta.py\u001b[0m in \u001b[0;36maugment_images\u001b[1;34m(self, images, parents, hooks)\u001b[0m\n\u001b[0;32m    820\u001b[0m         &quot;&quot;&quot;\n\u001b[0;32m    821\u001b[0m         \u001b[0miabase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_on_suspicious_multi_image_shapes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--&gt; 822\u001b[1;33m         return self.augment_batch_(\n\u001b[0m\u001b[0;32m    823\u001b[0m             \u001b[0mUnnormalizedBatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m             \u001b[0mparents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparents\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramFile\\anaconda\\envs\\tlc\\lib\\site-packages\\imgaug\\augmenters\\meta.py\u001b[0m in \u001b[0;36maugment_batch_\u001b[1;34m(self, batch, parents, hooks)\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0m_maybe_deterministic_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mbatch_inaug\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--&gt; 641\u001b[1;33m                 batch_inaug = self._augment_batch_(\n\u001b[0m\u001b[0;32m    642\u001b[0m                     \u001b[0mbatch_inaug\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m                     \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramFile\\anaconda\\envs\\tlc\\lib\\site-packages\\imgaug\\augmenters\\geometric.py\u001b[0m in \u001b[0;36m_augment_batch_\u001b[1;34m(self, batch, random_state, parents, hooks)\u001b[0m\n\u001b[0;32m   3048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3049\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-&gt; 3050\u001b[1;33m             batch.images = self._augment_images_by_samples(batch.images,\n\u001b[0m\u001b[0;32m   3051\u001b[0m                                                            samples)\n\u001b[0;32m   3052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramFile\\anaconda\\envs\\tlc\\lib\\site-packages\\imgaug\\augmenters\\geometric.py\u001b[0m in \u001b[0;36m_augment_images_by_samples\u001b[1;34m(self, images, samples)\u001b[0m\n\u001b[0;32m   3106\u001b[0m                     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-&gt; 3108\u001b[1;33m                 image_warped = tf.warp(\n\u001b[0m\u001b[0;32m   3109\u001b[0m                     \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3110\u001b[0m                     \u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramFile\\anaconda\\envs\\tlc\\lib\\site-packages\\skimage\\transform\\_warps.py\u001b[0m in \u001b[0;36mwarp\u001b[1;34m(image, inverse_map, map_args, output_shape, order, mode, cval, clip, preserve_range)\u001b[0m\n\u001b[0;32m    925\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m         \u001b[0mndi_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_to_ndimage_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--&gt; 927\u001b[1;33m         warped = ndi.map_coordinates(image, coords, prefilter=prefilter,\n\u001b[0m\u001b[0;32m    928\u001b[0m                                      mode=ndi_mode, order=order, cval=cval)\n\u001b[0;32m    929\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramFile\\anaconda\\envs\\tlc\\lib\\site-packages\\scipy\\ndimage\\interpolation.py\u001b[0m in \u001b[0;36mmap_coordinates\u001b[1;34m(input, coordinates, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[0;32m    388\u001b[0m     output = _ni_support._get_output(output, input,\n\u001b[0;32m    389\u001b[0m                                      shape=output_shape)\n\u001b[1;32m--&gt; 390\u001b[1;33m     _nd_image.geometric_transform(filtered, None, coordinates, None, None,\n\u001b[0m\u001b[0;32m    391\u001b[0m                                   output, order, mode, cval, None, None)\n\u001b[0;32m    392\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_tfms, valid_tfms, test_tfms = get_augmentations()\n",
    "# get train and validation dataloader\n",
    "train_dl, valid_dl = get_data(train_tfms=train_tfms, valid_tfms=valid_tfms)\n",
    "# get our loss func\n",
    "loss_fn = FocalLoss(alpha=0.25, gamma=2)\n",
    "\n",
    "model, opt = get_model(model_name='efficientnet-b3', lr=1e-5, wd=1e-2)\n",
    "\n",
    "model, accuracy_score = fit(epoch, train_dl, valid_dl, model, loss_fn, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Training finished, TOTAL epochs: {epoch}\\nSaving model as :{model_name}')\n",
    "torch.save(model.state_dict(), f'./models/{model_name}.pth')\n",
    "print('You can check your model in ./models')"
   ]
  }
 ]
}